import streamlit as st
import os
import subprocess
import glob
import time
import soundfile as sf
import numpy as np
from openai import OpenAI
import google.generativeai as genai
from streamlit_webrtc import webrtc_streamer, AudioRecorderFactory

# --- 1. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©) ---

def process_audio_and_summarize(api_keys, audio_file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì „ì²´ ìš”ì•½ ê³¼ì •ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    openai_key, google_key = api_keys
    summary = ""
    temp_folder = f"temp_chunks_{int(time.time())}"

    with st.spinner("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
        try:
            client = OpenAI(api_key=openai_key)
            genai.configure(api_key=google_key)
            model = genai.GenerativeModel('gemini-1.5-flash')

            chunk_files = split_audio_with_ffmpeg(audio_file_path, temp_folder)
            
            if chunk_files:
                progress_bar = st.progress(0, text="ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
                full_transcript = transcribe_audio_chunks(client, chunk_files, progress_bar)
                
                if full_transcript:
                    st.progress(1.0, text="í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ! Geminië¡œ ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    prompt = f"ë‹¤ìŒ íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ í˜•ì‹ì— ë§ì¶° Markdown ì–‘ì‹ìœ¼ë¡œ ë©‹ì§€ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n[íšŒì˜ë¡ í…ìŠ¤íŠ¸]\n{full_transcript}\n\n[ìš”ì•½ í˜•ì‹]\n### ğŸ“Œ í•µì‹¬ ìš”ì•½\n\n### ğŸ“ ìƒì„¸ ë‚´ìš©\n- \n\n### ğŸš€ Action Items\n- "
                    response = model.generate_content(prompt)
                    summary = response.text

        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            cleanup_temp_folder(temp_folder)
            if os.path.exists(audio_file_path):
                os.remove(audio_file_path)
    
    if summary:
        st.success("âœ… ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.markdown("---")
        st.markdown(summary)
        st.balloons()
    else:
        st.error("ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def split_audio_with_ffmpeg(file_path, temp_folder, chunk_duration_sec=1500):
    if not os.path.exists(temp_folder): os.makedirs(temp_folder)
    try:
        command = f'ffmpeg -i "{file_path}" -f segment -segment_time {chunk_duration_sec} -c copy "{os.path.join(temp_folder, "chunk_%03d.m4a")}"'
        subprocess.run(command, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return sorted(glob.glob(os.path.join(temp_folder, "chunk_*.m4a")))
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def transcribe_audio_chunks(client, chunk_files, progress_bar):
    full_transcript = ""
    total_chunks = len(chunk_files)
    for i, chunk_file in enumerate(chunk_files):
        try:
            with open(chunk_file, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file, response_format="text")
            full_transcript += transcript + " "
            progress_bar.progress((i + 1) / total_chunks, text=f"í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘... ({i+1}/{total_chunks})")
        except Exception as e:
            st.error(f"'{os.path.basename(chunk_file)}' ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
    return full_transcript

def cleanup_temp_folder(folder):
    if os.path.exists(folder):
        for file in os.listdir(folder): os.remove(os.path.join(folder, file))
        os.rmdir(folder)

# --- 2. ì‹¤ì‹œê°„ ë…¹ìŒì„ ìœ„í•œ í´ë˜ìŠ¤ (streamlit-webrtc) ---

class AudioRecorderFactory(AudioRecorderFactory):
    def __init__(self):
        self.frames = []

    def recv(self, frame):
        self.frames.append(frame.to_ndarray())
        return frame

    def get_audio_data(self):
        if not self.frames:
            return None
        # ëª¨ë“  ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê³  WAV íŒŒì¼ë¡œ ì €ì¥
        audio_data = np.concatenate([f.flatten() for f in self.frames])
        samplerate = self.frames[0].sample_rate
        
        # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
        temp_wav_path = "temp_recording.wav"
        sf.write(temp_wav_path, audio_data, samplerate)
        return temp_wav_path

# --- 3. Streamlit UI êµ¬ì„± ---

st.set_page_config(page_title="AI íšŒì˜ë¡ ìš”ì•½", page_icon="ğŸ™ï¸", layout="wide")
st.title("ğŸ™ï¸ AI íšŒì˜ë¡ ìš”ì•½ ì›¹ì•±")

with st.sidebar:
    st.header("API í‚¤ ì„¤ì •")
    openai_api_key = st.text_input("OpenAI API í‚¤", type="password", placeholder="sk-...")
    google_api_key = st.text_input("Google AI API í‚¤", type="password", placeholder="AIza...")
    st.info("API í‚¤ëŠ” ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì‚¬ë¼ì§€ë©°, ì„œë²„ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

tab1, tab2 = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ”´ ì‹¤ì‹œê°„ ë…¹ìŒ"])

with tab1:
    st.subheader("ì´ë¯¸ ë…¹ìŒëœ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ (MP3, M4A, WAV...)", type=['mp3', 'm4a', 'wav', 'mp4'])

    if uploaded_file:
        if st.button("íŒŒì¼ë¡œ ìš”ì•½ ì‹œì‘í•˜ê¸°", key="upload_button"):
            if not openai_api_key or not google_api_key:
                st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                with open(uploaded_file.name, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                process_audio_and_summarize((openai_api_key, google_api_key), uploaded_file.name)

with tab2:
    st.subheader("ì›¹ì•±ì—ì„œ ë°”ë¡œ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”.")
    
    webrtc_ctx = webrtc_streamer(
        key="audio-recorder",
        audio_recorder_factory=AudioRecorderFactory,
        media_stream_constraints={"video": False, "audio": True},
        in_recorder=True,
        out_recorder=False,
    )

    if not webrtc_ctx.state.playing:
        if webrtc_ctx.audio_recorder_factory:
            audio_file_path = webrtc_ctx.audio_recorder_factory.get_audio_data()
            if audio_file_path:
                st.audio(audio_file_path)
                if st.button("ì´ ë…¹ìŒìœ¼ë¡œ ìš”ì•½ ì‹œì‘í•˜ê¸°", key="record_button"):
                    if not openai_api_key or not google_api_key:
                        st.warning("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
                    else:

                        process_audio_and_summarize((openai_api_key, google_api_key), audio_file_path)

